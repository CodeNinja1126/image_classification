{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sustainable-battle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-automation",
   "metadata": {},
   "source": [
    "- 이미지 이름과 이미지의 경로, csv파일의 경로를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informed-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = ['normal', 'mask1', 'mask2', \n",
    "            'mask3', 'mask4', 'mask5', 'incorrect_mask']\n",
    "\n",
    "csv_path = '/opt/ml/input/data/train/train.csv'\n",
    "data_path = '/opt/ml/input/data/train/images'\n",
    "mask_image_frame = pd.read_csv(csv_path)\n",
    "\n",
    "test_csv_path = '/opt/ml/input/data/eval/info.csv'\n",
    "test_data_path = '/opt/ml/input/data/eval/images'\n",
    "\n",
    "eval_image_frame = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adopted-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  gender   race  age                    path\n",
       "0  000001  female  Asian   45  000001_female_Asian_45\n",
       "1  000002  female  Asian   52  000002_female_Asian_52\n",
       "2  000004    male  Asian   54    000004_male_Asian_54\n",
       "3  000005  female  Asian   58  000005_female_Asian_58\n",
       "4  000006  female  Asian   59  000006_female_Asian_59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_image_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorporate-jewel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_image_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-plymouth",
   "metadata": {},
   "source": [
    "- 데이터셋의 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "processed-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, data_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv_file 경로\n",
    "            data_path (string): data_path 경로\n",
    "            transform (string): 샘플에 적용될 transform(전처리)\n",
    "        \"\"\"\n",
    "        self.mask_image_frame = pd.read_csv(csv_file)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mask_image_frame) * 7\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        idx //= 7\n",
    "        img_path = os.path.join(self.data_path, \n",
    "                                self.mask_image_frame.loc[idx,'path'])\n",
    "        \n",
    "        img_type_list = ['.png', '.jpg', '.jpeg']\n",
    "        for img_type in img_type_list:\n",
    "            if os.path.isfile(os.path.join(img_path, img_name[idx%7] + img_type)):\n",
    "                image = Image.open(os.path.join(img_path, img_name[idx%7] + img_type))\n",
    "                break\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = { 'status': idx%7,\n",
    "                  'gender': self.mask_image_frame.loc[idx,'gender'],\n",
    "                  'age': self.mask_image_frame.loc[idx,'age']\n",
    "                 }\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "twelve-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationSet(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, data_path, transform=None):\n",
    "        self.mask_image_frame = pd.read_csv(csv_file)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_image_frame)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = os.path.join(self.data_path, \n",
    "                               self.mask_image_frame.loc[idx, 'ImageID'])\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-server",
   "metadata": {},
   "source": [
    "- torchvision의 transforms 기능으로 전처리 및 augmentation, 그리고 data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impaired-sport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 1.2899,  1.2899,  1.2899,  ...,  1.3755,  1.3755,  1.3927],\n",
      "         [ 1.2899,  1.2899,  1.2899,  ...,  1.3755,  1.3755,  1.3927],\n",
      "         [ 1.2899,  1.2899,  1.2899,  ...,  1.3755,  1.3755,  1.3927],\n",
      "         ...,\n",
      "         [ 0.2111,  0.1768,  0.1254,  ...,  0.3138,  0.1939, -0.0629],\n",
      "         [ 0.2111,  0.1768,  0.1597,  ...,  0.2967,  0.3138,  0.3138],\n",
      "         [ 0.2282,  0.1939,  0.1597,  ...,  0.2453,  0.2967,  0.3994]],\n",
      "\n",
      "        [[ 1.4307,  1.4307,  1.4307,  ...,  1.5182,  1.5182,  1.5357],\n",
      "         [ 1.4307,  1.4307,  1.4307,  ...,  1.5182,  1.5182,  1.5357],\n",
      "         [ 1.4307,  1.4307,  1.4307,  ...,  1.5182,  1.5182,  1.5357],\n",
      "         ...,\n",
      "         [ 0.2752,  0.2402,  0.2402,  ..., -0.4426, -0.5826, -0.8102],\n",
      "         [ 0.2927,  0.2402,  0.2752,  ..., -0.5126, -0.4776, -0.4776],\n",
      "         [ 0.3102,  0.2577,  0.2752,  ..., -0.6001, -0.5301, -0.4251]],\n",
      "\n",
      "        [[ 1.5768,  1.5768,  1.5768,  ...,  1.6988,  1.6988,  1.7163],\n",
      "         [ 1.5768,  1.5768,  1.5768,  ...,  1.6988,  1.6988,  1.7163],\n",
      "         [ 1.5768,  1.5768,  1.5768,  ...,  1.6988,  1.6988,  1.7163],\n",
      "         ...,\n",
      "         [ 0.4265,  0.4091,  0.3916,  ..., -0.5147, -0.6018, -0.8458],\n",
      "         [ 0.4265,  0.4091,  0.4265,  ..., -0.5670, -0.4973, -0.4973],\n",
      "         [ 0.4439,  0.4265,  0.4265,  ..., -0.6367, -0.5495, -0.4275]]]), {'status': 0, 'gender': 'female', 'age': 45})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2db405be914d7f89595a12b36dfe9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64ff401c5854d1185517844a1c3921c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((384,384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "dataset = MaskImageDataset(csv_path, data_path, data_transform)\n",
    "data_loader = DataLoader(dataset,\n",
    "                            shuffle=True,\n",
    "                            batch_size=10, \n",
    "                            num_workers=16,)\n",
    "\n",
    "for data in tqdm.notebook.tqdm(data_loader):\n",
    "    pass\n",
    "\n",
    "dataset = ValidationSet(test_csv_path, test_data_path, data_transform)\n",
    "data_loader = DataLoader(dataset,\n",
    "                            shuffle=True,\n",
    "                            batch_size=10, \n",
    "                            num_workers=16,)\n",
    "\n",
    "for data in tqdm.notebook.tqdm(data_loader):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-muslim",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
