{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "increased-provision",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-force",
   "metadata": {},
   "source": [
    "- 이미지 이름과 이미지의 경로, csv파일의 경로를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fallen-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = ['normal', 'mask1', 'mask2', \n",
    "            'mask3', 'mask4', 'mask5', 'incorrect_mask']\n",
    "\n",
    "csv_path = '/opt/ml/input/data/train/train.csv'\n",
    "data_path = '/opt/ml/input/data/train/images'\n",
    "mask_image_frame = pd.read_csv(csv_path)\n",
    "\n",
    "test_csv_path = '/opt/ml/input/data/eval/info.csv'\n",
    "test_data_path = '/opt/ml/input/data/eval/images'\n",
    "\n",
    "eval_image_frame = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coastal-theta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  gender   race  age                    path\n",
       "0  000001  female  Asian   45  000001_female_Asian_45\n",
       "1  000002  female  Asian   52  000002_female_Asian_52\n",
       "2  000004    male  Asian   54    000004_male_Asian_54\n",
       "3  000005  female  Asian   58  000005_female_Asian_58\n",
       "4  000006  female  Asian   59  000006_female_Asian_59"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_image_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "noble-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_image_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-generation",
   "metadata": {},
   "source": [
    "- 데이터셋의 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bearing-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, data_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv_file 경로\n",
    "            data_path (string): data_path 경로\n",
    "            transform (string): 샘플에 적용될 transform(전처리)\n",
    "        \"\"\"\n",
    "        self.mask_image_frame = pd.read_csv(csv_file)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mask_image_frame) * 7\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        idx //= 7\n",
    "        img_path = os.path.join(self.data_path, \n",
    "                                self.mask_image_frame.loc[idx,'path'])\n",
    "        \n",
    "        img_type_list = ['.png', '.jpg', '.jpeg']\n",
    "        for img_type in img_type_list:\n",
    "            if os.path.isfile(os.path.join(img_path, img_name[idx%7] + img_type)):\n",
    "                image = Image.open(os.path.join(img_path, img_name[idx%7] + img_type))\n",
    "                break\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = { 'status': idx%7,\n",
    "                  'gender': self.mask_image_frame.loc[idx,'gender'],\n",
    "                  'age': self.mask_image_frame.loc[idx,'age']\n",
    "                 }\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "north-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationSet(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, data_path, transform=None):\n",
    "        self.mask_image_frame = pd.read_csv(csv_file)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_image_frame)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = os.path.join(self.data_path, \n",
    "                               self.mask_image_frame.loc[idx, 'ImageID'])\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-frequency",
   "metadata": {},
   "source": [
    "- torchvision의 transforms 기능으로 전처리 및 augmentation, 그리고 data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dirty-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbed888756354cebb0a97cf1397bb59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ce2de5a3834288ad54867fcef9349c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((384,384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "dataset = MaskImageDataset(csv_path, data_path, data_transform)\n",
    "data_loader = DataLoader(dataset,\n",
    "                            shuffle=True,\n",
    "                            batch_size=10, \n",
    "                            num_workers=16,)\n",
    "\n",
    "for data in tqdm.notebook.tqdm(data_loader):\n",
    "    pass\n",
    "\n",
    "dataset = ValidationSet(test_csv_path, test_data_path, data_transform)\n",
    "data_loader = DataLoader(dataset,\n",
    "                            shuffle=True,\n",
    "                            batch_size=10, \n",
    "                            num_workers=16,)\n",
    "\n",
    "for data in tqdm.notebook.tqdm(data_loader):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-stylus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
